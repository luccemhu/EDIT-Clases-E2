---
title: "**<b style = 'color : #E34B2A;'>Regresión Lineal Multivariada (I)</b>**"
subtitle: 'Profesor: <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel MAGALLANES REYES, Ph.D.</a>'
date: "2023-07-26"
author: "Editors: [Gianfranco Romero](https://github.com/GianfrancoRomero), \n a20196091@pucp.edu.pe & \n [Joel Hu](https://github.com/luccemhu), \n a20196510@pucp.edu.pe"
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: false
    highlight: github
    code_folding: "show"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

<a id='beginning'></a>

Más allá de la Regresión Lineal (OLS)
============================================================
Utilicemos los datos del INEI: XI Censo de Población y VI Censo de Vivienda del 2007.

Indicadores a nivel de distrito (por departamento y provincia):

-   Número de personas que tienen algún tipo de seguro.  `segu`
-   Porcentaje de Trabajadores Independientes o por cuenta propia no profesionales. `inde`
-   Porcentaje de personas analfabetas de 15 años y más. `analf15`
-   Total de habitantes (2007). `pob`

```{r getdata}
#rm(list = ls()) # clear memory
#knitr::knit_hooks$set(inline = as.character) # inline as string

gitLink = "https://github.com/luccemhu/EDIT-Clases-E2/raw/main/sesion-3/salud.xlsx"
salud = rio::import(gitLink)

# simpler names
oldnames = names(salud)
newnames = c("depa", "prov", "dis", "segu", "inde", "analf15", "pob")
names(salud) = newnames

# display table
#library(magrittr) # needed for pipe |> 
#salud |> rmarkdown::paged_table()
```

Por ejemplo:

> H1: A nivel distrital, la cantidad de personas con algún seguro de salud `segu` está afectada por el nivel analfabetismo `analf15`.

Podríamos intentar una regresión lineal:
```{r rl1,warning=FALSE, message=FALSE, results='asis'}
library(knitr)
library(modelsummary)

h1 = formula(segu ~ analf15)
rl1 = lm(h1, data = salud)

model1 = list('OLS asegurados (I)' = rl1)
modelsummary(model1, title = "Resumen de Regresion Lineal",
             stars = TRUE, output = "kableExtra")
```

-   El **covariado** salió con un valor absoluto alto, negativo, y significativo (es muy poco probable - menos de 0.1% - que no tenga efecto), pero con un **R-2 ajustado muy bajo**. Como el modelo no nos da buen *ajuste*, es muy probable que la evaluación del modelo no sea satisfactoria. Comprobamos con los diagnósticos de regresión que difícilmente este modelo puede ser útil:

```{r evaluacionrl1,fig.cap="Diagnósticos para el modelo OLS asegurados (I)"}
par(mfrow = c(2, 2))  
plot(rl1, 1,caption = ''); title(main = "Linealidad")
plot(rl1, 2, caption = ''); title(main = "Normalidad")
plot(rl1, 3, caption = ''); title(main = "Homocedasticidad")
plot(rl1, 5, caption = ''); title(main = "Influyentes")
```

Podríamos mejorar este modelo si controlásemos el tamaño de la población (`pob`) en el modelo:

```{r rl12,warning=FALSE, message=FALSE, results='asis'}
library(knitr)
library(modelsummary)

h1control = formula(segu ~ analf15 + pob) # Añadimos la variable constante `pob`

rl2 = lm(h1control, data = salud)

modelslm = list('OLS asegurados (I)' = rl1,
                'OLS asegurados (II)' = rl2)
modelsummary(modelslm, title = "Regresiones Lineales",
             stars = TRUE, output = "kableExtra")
```

-   Se ve una gran mejora en el R-2 ajustado con el modelo II.

Sus gráficas de diagnóstico muestran un mejor escenario (*el chunk de abajo*), pero nuestro predictor dejó de ser significativo ante la presencia de la variable de control `pob`. **Quiza *primero* debimos analizar la naturaleza de la V. Dependiente `segu`**:

```{r eval=FALSE, evaluacionrl2,fig.cap="Diagnósticos para el modelo OLS asegurados (II)"}
# Diagnósticos para el modelo OLS asegurados (II): 
par(mfrow = c(2, 2))  
plot(rl2, 1,caption = '');title(main = "Linealidad")
plot(rl2, 2, caption = '');title(main = "Normalidad")
plot(rl2, 3, caption = '');title(main = "Homocedasticidad")
plot(rl2, 5, caption = '');title(main = "Influyentes")
```

Histograma de la V.D `segu`:

```{r hisVD,message=FALSE,fig.cap="Descripción de la Variable Dependiente"}
library(ggplot2)
VarDep = salud$segu
descris = list(min = min(VarDep),
               max = max(VarDep),
               media = round(mean(VarDep), 2),
               var = round(var(VarDep), 2),
               asim = round(e1071::skewness(VarDep), 2))

base = ggplot(data = salud, aes(x = segu)) + theme_classic()
hist = base + geom_histogram(bins = 50)

histInfo = hist + annotate("text", x = 100000, y = 1000,
                           color='grey50',
                           label = paste0("Minimo:",descris$min))
histInfo = histInfo + annotate("text", x = 100000, y = 800,
                               color = 'grey50',
                               label = paste0("Máximo: ", descris$max))
histInfo = histInfo + annotate("text", x = 100000, y = 600,
                               color = 'grey50',
                               label = paste0("Media: ", descris$media))
histInfo = histInfo + annotate("text", x = 100000, y = 400,
                               color = 'grey50',
                               label = paste0("Varianza: ", descris$var))
histInfo = histInfo + annotate("text", x = 100000, y = 200,
                               color = 'grey50',
                               label = paste0("Sesgo: ", descris$asim))
histInfo
```

- 1. El histograma nos muestra una distribución con **sesgo positivo (a la derecha)**. Es decir, **no forma una campana de Gauss**, por ello, debilitaría los calculos de significancia si los datos **no siguen una tendencia lineal**. (Se puede transformar la V.D., pero la interpretación sería compleja).

- 2. Advertimos que nuestra **V.D. representa conteos**: valores enteros positivos. Por ello, la regresión lineal tuvo problemas, ya que asume que la V.D. tiene valores reales y no acotados.

**Regresión Poisson [RP]**
============================================================

Supuestos del RP [Glen, 2016]:

1.  **Variable Respuesta**: cuantitativa discreta
    - Es un conteo (Y) por unidad de tiempo o espacio, que puede ser descrita por la distribución Poisson. 
    - Puede además ser un ratio ($\lambda$) cuando la unidad de tiempo o espacio varía para cada conteo.

2.  **Independencia** Las observaciones (filas) no deben tener relación entre sí.
3.  **Media=Varianza**: equidispersión
    Otros casos: 
    - Media > Varianza: sobredispersión
    - Media < Varianza: Subdispersión
    
Por definición, la media de una variable que se distribuye como Poisson debe ser igual a su varianza (equidispersión). Si la varianza supera significativamente a la media hablamos de sobredispersión; pero si la media fuera mucho mayor que la varianza tendríamos subdispersión.

4.  **Linealidad**: El logaritmo de la V.D. debe ser una función lineal.

Ahora, usemos la RP en la H1:

- comparándolos con el resultado de la regresión lineal controlada por la población:

```{r rp1rl2,warning=FALSE, message=FALSE, results='asis'}

rp1 = glm(h1, data = salud, 
        offset = log(pob), # Exposure # Variable control 
        family = poisson(link = "log")) # Poisson

# displaying results
modelslmpoi = list('OLS asegurados (II)'=rl2,
                 'POISSON asegurados'=rp1)

modelsummary(modelslmpoi, title = "Regresiones OLS y Poisson",
             stars = TRUE,
             output = "kableExtra")
```

Ahora que tenemos ambas regresiones en la Tabla \@ref(tab:rp1rl2), vemos que el modelo Poisson le devuelve efecto a la independiente. Nótese que la Poisson está modelando los conteos, teniendo en cuenta la exposición (*exposure*), añadida usando *offset*. Esto no siempre es necesario, pero en este caso si lo era pues necesitamos representar controlar la *exposure* de manera explícita (la población) [^1].

[^1]: No sería diferente si tuvieramos *hijos por hogar*, *postulaciones por político*.

La Tabla \@ref(tab:rp1rl2) muestra dos modelos que no se pueden comparar fácilmente, pero podemos verlo de manera gráfica en la Figura \@ref(fig:compare_olspoi).

```{r compare_olspoi,fig.cap="Comparando modelos via valores calculados"}
par(mfrow = c(1, 2))  # divide screen 1 row 2 columns
plot(salud$segu, fitted(rp1),
     ylim = c(0, 365000));title(main = "Original versus Poisson")
plot(salud$segu, fitted(rl2),
     ylim = c(0, 365000));title(main = "Original versus OLS \ncontrolando población")
```

La Figura \@ref(fig:compare_olspoi) muestra que los valores obtenidos por la regresiones (*fitted values*) se relacionan muy bien con los valores originales. Ambas servirían para predecir; pero sólo la Poisson le da significancia al predictor de interés.

## Interpretación

Ahora que sabemos cuándo usar una regresión Poisson, alteremos la hipótesis anterior así:

> A nivel distrital, la cantidad de personas con algun seguro de salud está afectada por el nivel analfabetismo y por la presencia de trabajadores independientes.

```{r rp1rp2,warning=FALSE, message=FALSE, results='asis'}

h2=formula(segu~analf15 + inde)
    
rp2=glm(h2, data = salud, offset = log(pob),
        family = poisson(link = "log"))


modelsPois=list('POISSON asegurados (I)' = rp1,
                'POISSON asegurados (II)' = rp2)
modelsummary(modelsPois, 
             title = "Regresiones Poisson anidadas",
             stars = TRUE,
             output = "kableExtra")
```

La interpretación de la Tabla \@ref(tab:rp1rp2) NO es tan directa como lo era en la regresión lineal. Sin hacer ningun cálculo, aquí podemos ver:

-   que para el segundo modelo ambos predictores son significativos;
-   que a mayor analfabetismo, mayor cantidad de asegurados;
-   que a mayor cantidad de trabajadores independientes, menor cantidad de asegurados.

Sin embargo, no es tan sencilla la interpretación de los coeficientes de la la Tabla \@ref(tab:rp1rp2). Para tener una mejor idea, debemos hacer cálculos.

Tengamos primero en cuenta lo que la regresión Poisson ha calculado usando la Ecuación \@ref(eq:poi):

```{=tex}
\begin{equation}
\log(Y) = \log(\lambda) =\alpha + \beta \cdot X + \epsilon (\#eq:poi)
\end{equation}
```
Cuando el *exposure* es constante modelamos conteos (Y); cuando no lo es modelamos ratios ($\lambda$)[^2]. Pero, como vemos en la Ecuación \@ref(eq:poi), los coeficiente necesitan ser exponenciados para saber el efecto sobre Y. Veamos la Tabla \@ref(tab:exp-rp2).

[^2]: los conteos con *offset*.

```{r exp-rp2,warning=FALSE, message=FALSE, results='asis'}

f <- function(x) format(x, digits = 4, scientific = FALSE)
modelsummary(modelsPois,
             fmt=f,
             exponentiate = T, 
             statistic = 'conf.int',
             title = "EXP() de la Regresión Poisson para Interpretación",
             stars = TRUE,
             output = "kableExtra")
# simple version:
#cbind(exp(coef(rp2)),exp(confint(rp2)))
```

La Tabla \@ref(tab:exp-rp2) tiene los coeficientes exponenciados, así mismo, muestra los intervalos de confianza (exponenciados) en vez de los errores típicos. Nota que mientras en la regresión lineal no deseábamos que nuestro coeficiente esté cerca al cero, es decir, que su intervalo de confianza no incluya al *cero*, aquí no deseamos que el intervalo de confianza incluya al *uno*. Una vez exponenciado, podemos interpretar los coeficientes de manera más sencilla. Así, para el modelo II se ve que por cada unidad que aumente el analfabetismo la cantidad esperada de asegurados se multiplica por 1.016, es decir, aumentaría en un 1.6% (100x\|1-1.016\|). De igual manera, por cada unidad que aumente los trabajadores independientes, la cantidad esperada de asegurados se multiplica por 0.99, es decir, disminuiría en 1% (100x\|1-0.99\|) [@choueiry_interpret_2022]. Nótese que esta regresión propone un efecto multiplicativo sobre el valor medio de la respuesta (la regresión OLS o Gaussiana propone un efecto aditivo).

````{=html}
<!--
```{r, echo=FALSE, eval=FALSE}
##robustes
cov.rp2 = sandwich::vcovHC(rp2, type="HC0")
Rob.std.err = sqrt(diag(cov.rp2))
summaryRobusto = cbind(Estimate= coef(rp2), 
                   "SE robusto" = Rob.std.err,
                  "Pr(>|z|)" = 2 * pnorm(abs(coef(rp2)/Rob.std.err), 
                  lower.tail=FALSE),
                   LI = coef(rp2) - 1.96 * Rob.std.err,
                   LS = coef(rp2) + 1.96 * Rob.std.err)

summaryRobusto
```

```{r, eval=FALSE}
library(msm)
Robustos <- deltamethod(list(~ exp(x1), ~ exp(x2),~ exp(x3)),
                     coef(rp2), cov.rp2)

Exp.summaryRobusto <- exp(summaryRobusto[, -3])

Exp.summaryRobusto[, "SE robusto"] <- Robustos

Exp.summaryRobusto
```
-->
````

# Equidispersión

Uno de los supuestos en la Regresión Poisson es que la **media** y la **varianza** sean iguales. De los estadigrafos de la Figura \@ref(fig:hisVD) se mostró que estos valores no están cercanos, de hecho la razón varianza - media es `r round(descris$var/descris$media,2)`. Aquí es clara la sobredispersión, pero en caso haya dudas podemos poner a prueba la *hipótesis de equidispersion* [@hilbe_statistical_2017]. Veamos la Tabla \@ref(tab:tabla-disper).

```{r tabla-disper, message=FALSE}
overdispersion = AER::dispersiontest(rp2, alternative = 'greater')$p.value <
  0.05
underdispersion = AER::dispersiontest(rp2, alternative = 'less')$p.value <
  0.05
# tabla
testResult = as.data.frame(rbind(overdispersion, underdispersion))
names(testResult) = 'Es probable?'

testResult |> kable(caption = "Test de Equidispersión") |> 
  kableExtra::kable_styling()
```

La Tabla \@ref(tab:tabla-disper) muestra que es altamente improbable que la varianza sea igual a la media, por lo que se opta por aceptar que lo más probable es que tengamos sobredispersión.

## La Quasi Poisson

La presencia de sobredispersión puede tratarse con la *quasipoisson*; veamos la Tabla \@ref(tab:rqp).

```{r rqp, warning=FALSE, message=FALSE, echo=TRUE,results='asis'}
rqp = glm(h2, data = salud, offset = log(pob),
          family = quasipoisson(link = "log"))

modelsPQP=list('POISSON asegurados (II)' = rp2,
               'QUASIPOISSON asegurados (II)' = rqp)

modelsummary(modelsPQP, title = "Regresiones Poisson y QuasiPoisson",
             stars = TRUE,
             output = "kableExtra")
```

la Tabla \@ref(tab:rqp) nos muestra cosas interesantes:

-   Los coeficientes son los mismos para ambos modelos:

```{r, message=FALSE}
library(arm)
cbind(coefPoi = coef(rp2), coefQuasiPoi = coef(rqp))

```

-   Pero no los errores típicos no:

```{r}
cbind(sePoi = se.coef(rp2), seQuasiPoi = se.coef(rqp))
```

-   Nota además ambos modelos tienen diferente parámetro de dispersion:

```{r}
summary(rqp)$dispersion; summary(rp2)$dispersion
```

La regresión quasipoisson lidia mejor con la sobredispersión, cuyo efecto concreto fue sobre los errores típicos, lo que afectaría la significancia de los predictores. De ahí que un mejor intervalo de confianza sería:

```{r exp-rqp,warning=FALSE, message=FALSE, results='asis'}
modelsQPexp=list('QuasiPoisson asegurados (II) exponenciado'=rqp)

f <- function(x) format(x, digits = 4, scientific = FALSE)
modelsummary(modelsQPexp, fmt = f,
             exponentiate = T,
             statistic = 'conf.int',
             title = "EXP() de la Regresión Quasi Poisson (II) para Interpretación",
             stars = TRUE,
             output = "kableExtra")
```

## La Binomial Negativa

Otra alternativa ante la sobredispersión es usar la *regresión binomial negativa*. Comparemos todas la regresiones exponenciadas, como se ve en la Tabla \@ref(tab:exp-rbn).

```{r exp-rbn,warning=FALSE, message=FALSE, results='asis'}
h2off = formula(segu ~ analf15 + inde + offset(log(pob)))
rbn = glm.nb(h2off, data = salud)

modelsQP_BN = list('Poisson asegurados (II)' = rp2,
                   'QuasiPoisson asegurados (II)' = rqp,
                   'Binomial Negativa asegurados (II)' = rbn)

f <- function(x) format(x, digits = 4, scientific = FALSE)
modelsummary(modelsQP_BN, fmt = f,
             exponentiate = T,
             statistic = 'conf.int',
             title = "EXP() de la Regresiones Poisson, Quasi Poisson  y Binomial Negativa",
             stars = TRUE,
             output = "kableExtra")
```

Nótese en la Tabla \@ref(tab:exp-rbn) que los coeficientes obtenidos en la regresión binomial negativa son diferentes a los demas.

# Comparación de modelos

Para la comparación podemos usar el anova, esta vez pidiendo un test chi-cuadrado; veamos el resultado en la Tabla \@ref(tab:anovarall).

```{r anovarall}
anova(rp2, rqp, rbn, test = "Chisq") |>
  kable(caption = "Tabla ANOVA para comparar modelos") |> 
  kableExtra::kable_styling(full_width = FALSE)
```

La caída del *Deviance* es tanta para el último caso que la mejor opción es la binomial negativa. Por lo general, la binomial negativa es más utilizada que la quasipoisson, pero la binomial negativa no es apropiada para la subdispersión, mientras que la quasipoisson sí se usa para ese caso. Una manera adicional de comparar es la gráfica. Así, la Tabla \@ref(tab:exp-rbn) se puede ver de manera gráfica en la Figura \@ref(fig:finplots).

```{r finplots, fig.cap="Comparación visual de modelos", message=FALSE, warning=FALSE}
library(ggplot2)
dotwhisker::dwplot(list(Poisson = rqp,
                        CuasiPoisso = rqp,
                        BinomialNegativa = rbn), exp = T) + 
  scale_y_discrete(labels = c("trabajo\nindependiente", "analfabetismo")) + 
  scale_color_discrete(name = "Modelos para:\nCantidad de Asegurados") + 
  geom_vline(xintercept = 1, colour = "grey60", linetype = 2)
```

Finalmente, podemos calcular los coeficientes estandarizados [@ibm_spss_computing_2020] para saber cuál de los predictores tiene mayor efecto (ver Tabla \@ref(tab:stdCoefs)).

```{r stdCoefs}
sdVD = sd(salud$segu)
sdVIs = apply(salud[, c("analf15", "inde")], 2, sd)
DF = list(Poisson = sdVIs * coef(rp2)[c(2, 3)] / sdVD,
          CuasiPoisson = sdVIs * coef(rqp)[c(2, 3)] / sdVD,
          BinomNegativa = sdVIs * coef(rbn)[c(2, 3)] / sdVD) |> 
  data.frame()

DF |> kable(caption = 
              "Coeficientes Standarizados (ordenar vía valores absolutos)") |>
  kableExtra::kable_styling(full_width = F)

```

<br></br> <br></br> [Comienzo](#beginning) <br></br> <br></br>
