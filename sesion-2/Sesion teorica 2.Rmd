---
title: "**<b style = 'color : #E34B2A;'>Diagnósticos de la regresión</b>**"
subtitle: 'Profesor: <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel MAGALLANES REYES, Ph.D.</a>'
date: "2023-07-25"
author: "Editors: [Gianfranco Romero](https://github.com/GianfrancoRomero), \n a20196091@pucp.edu.pe & \n [Joel Hu](https://github.com/luccemhu), \n a20196510@pucp.edu.pe"
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: false
    highlight: github
    code_folding: "show"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

<a id='beginning'></a>

I. Construcción de un modelo
============================================================

- Utilizando el caso de "Pavimentando con votos", armaremos un modelo de regresión lineal, al cual se le aplicarán diagnósticos para determinar su poder para predecir

## Preparación de los datos

```{r}
LinkData='https://github.com/luccemhu/EDIT-Clases-E2/raw/main/sesion-2/pavimentando.csv'
pcv=read.csv(LinkData) #Es necesario usar este código, pues el archivo está en formato csv
```

```{r}
seleccion=c("consejocomunal","ejecucion","uribista","priorizado")
pcv[,seleccion]=lapply(pcv[,seleccion],as.factor) #Convertimos estas variables a tipo factor
```

## Construcción de un modelo

- Se busca explicar la variable `apropiaciondolar`, para lo cual se pueden probar diferentes variables que la teoría nos sugiere

- Luego de comparar diferente modelos (revisar sesión teórica 1), se llega a la conclusión de que el mejor modelo es el siguiente:

```{r}
modelo=formula(apropiaciondolar~pctopo+consejocomunal+poblacioncienmil)
```

```{r}
library(stargazer)
reg=lm(modelo,data=pcv)
stargazer(reg,type = "text",intercept.bottom = FALSE)
```

El cual se puede representar de la siguiente manera:

$$apropiaciondolar = `r reg$coefficients[1]` + `r reg$coefficients[2]` \cdot pctopo + `r reg$coefficients[3]` \cdot consejocomunal1 + `r reg$coefficients[4]` \cdot poblacioncienmil + \epsilon$$

II. Diagnósticos de regresión
============================================================

- Para determinar si el modelo construído tiene poder para predecir, se le pueden aplicar diferentes diagnósticos

- Cabe resaltar que estos diagnósticos se realizan en la parte final de la investigación. El modelo sigue siendo válido para el caso estudiado (validez interna), por lo que lo que se está evaluando es si el modelo sirve para otros casos (validez externa)

## 1. Linealidad

- Se grafican los valores esperados con los residuos

- Lo ideal es que la línea roja tienda a ser horizontal y se acerce al valor 0 del eje Y

```{r}
plot(reg, 1)
```

- En este caso, podemos ver que los residuos tienden a acumularse en la parte izquierda del gráfico, y la línea roja no es del todo horizontal, especialmente en la parte izquierda

- Se podría decir que, en este caso, el modelo aparentemente no tendría linealidad, por lo que no es un buen predictor

## 2. Homocedasticidad

- Se estandariza el error y se le saca la raíz cuadrada, por lo que todos los errores se vuelven positivos

- La homocedasticidad implicaría que el error es igual a lo largo de cualquier valor del eje X (línea roja horizontal)

```{r}
plot(reg, 3)
```

- Podemos ver que el error tiende a acumularse en los valores menores del eje X. Esto es de esperar, dada la distribución del residuo en el diagnóstico de linealidad

- El modelo presenta heterocedasticidad

### Test de Breusch-Pagan

- H0: El modelo presenta homocedasticidad

```{r}
library(lmtest)
bptest(reg)
```

- Viendo el p-value (<0.05), confirmamos que el modelo presenta heterocedasticidad, por lo que no es un buen predictor

## 3. Normalidad de los residuos

- Lo ideal es que los residuos tengan una distribución normal

```{r}
plot(reg, 2)
```

- En este caso, los residuos se alejan de la línea en la parte derecha del gráfico, por lo que no existe una distribución normal de los residuos

- El modelo no es muy buen predictor

### Test de Shapiro

- H0: Los residuos tienen una distribución normal

```{r}
shapiro.test(reg$residuals)
```

- Con un p-value menor a 0.05, confirmamos que los residuos no tienen una distribución normal

## 4. No multicolinealidad

- La multicolinealidad implica que existe una alta correlación entre las V.I. seleccionadas, lo cual haría redundante incluir ciertas variables

- Lo ideal es que no exista colinealidad

- En el text de VIF, si una variable tiene un puntaje mayor a 5, es problemática y debería eliminarse

```{r}
library(DescTools)
VIF(reg)
```

- En este caso, todas las variables son menores a 5, por lo que no tenemos que eliminar ninguna variable del modelo

## 5. Valores influyentes

- Existen casos que son tan particulares que pueden afectar a la regresión del modelo

- De encontrarse, se puede optar por eliminarlos, lo cual cambiará la regresión del modelo

- En el gráfico, los valores influyentes son aquellos que están fuera de la distancia de Cook

```{r}
plot(reg, 5)
```

- El caso 146 es influyente

- Podemos confirmar esto con el siguiente código

```{r}
checkReg=as.data.frame(influence.measures(reg)$is.inf)
checkReg[checkReg$cook.d & checkReg$hat,]
```

- Nuevamente, se señala al caso 146 como un valor influyente

[Comienzo](#beginning)