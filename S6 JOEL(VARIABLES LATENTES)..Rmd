---
title: "**<b style = 'color : #E34B2A;'>Análisis de Variables Latentes</b>**"
subtitle: 'Profesor: <a href="http://www.pucp.edu.pe/profesor/jose-manuel-magallanes/" target="_blank">Dr. José Manuel MAGALLANES REYES, Ph.D.</a>'
date: "2023-07-26"
author: "Editors: [Gianfranco Romero](https://github.com/GianfrancoRomero), \n a20196091@pucp.edu.pe & \n [Joel Hu](https://github.com/luccemhu), \n a20196510@pucp.edu.pe"
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: false
    highlight: github
    code_folding: "show"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```
<a id='beginning'></a>

Muchas veces queremos saber si algun conjunto de variables representa algun *concepto*, al cual se le denomina técnicamente *variable latente*. Las técnicas son variadas, pero aquí aplicaremos análisis factorial: el exploratorio y el confirmatorio para tratar de *reducir* varias variables en otra u otras más simples.

````{=html}
<!--

-->
````
# Preprocesamiento (Revisar el `.rmd` sobre este paso):



Para esta sesión trabajaremos con la data de:

-   [Índice de Desarrollo Humano](https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_%C3%ADndice_de_desarrollo_humano)

-   [Índice de Democracia](https://es.wikipedia.org/wiki/%C3%8Dndice_de_democracia)

## Carga de datos

Para esta etapa vamos a proceder a *scrapear* las dos páginas web, con la ayuda de la biblioteca *htmltab*. La descarga utilizará el *xpath* de la tabla de interés.

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
rm(list = ls())

library(htmltab)

# links
WhereIDH=list(page="https://es.wikipedia.org/wiki/Anexo:Pa%C3%ADses_por_%C3%ADndice_de_desarrollo_humano", 
              xpath='//*[@id="mw-content-text"]/div[1]/table[6]') # Esto se actualiza
WhereDEMO=list(page="https://es.wikipedia.org/wiki/%C3%8Dndice_de_democracia",
               xpath='//*[@id="mw-content-text"]/div[1]/div[2]/div/table/tbody') # Esto se actualiza


#carga
idh  = htmltab(doc = WhereIDH$page, 
               which  = WhereIDH$xpath,
               encoding = "UTF-8")
demo  = htmltab(doc = WhereDEMO$page, 
               which  = WhereDEMO$xpath,
               encoding = "UTF-8")
```

## Limpieza

Por lo general, la data scrapeada presenta diversas 'impurezas'. Veámos qué se necesita 'limpiar'.

-   **Nombres de columnas**: Hay que tratar de tener nombres simples, sin espacios ni caracteres especiales. Si se desea mantener nombres descriptivos, puede hacerse uso de guiones bajos (underscores) o formato *CamelCase*.

Los nombres de la data *idh* son muy largos, con caracteres especiales, en español, y muchos espacios en blancos.

```{r}
names(idh)
```

Los nombres de la data *demo* no son muy largos, con caracteres en español, y muchos espacios en blancos.

```{r}
names(demo)
```

Por lo visto, hay que cambiar los nombres en ambas tablas.

```{r}
# en IDH
## cambio total
newNames = c('Pais', 'EsperanzaVida', 'EscolaridadDuracion', 'EscolaridadPromedio', 
             'PBI')
names(idh) = newNames

# en DEMO
## Capitalizar
library(stringr)
names(demo) = str_to_title(names(demo))

library(tidyverse)
demo = demo |> select(2:8)

## sin tildes ni ñs.
library(stringi)
names(demo) = stri_trans_general(str = names(demo),
                                 id = "Latin-ASCII")
## sin espacios
names(demo) = gsub(" ", "", names(demo))
```

-   **Valores en las celdas**: Por lo general, hay que asegurarse que no haya espacios en blanco ni al inicio ni al final de cada valor en una celda.

```{r}
idh[, ] = lapply(idh[, ], trimws, whitespace = "[\\h\\v]")

demo[, ] = lapply(demo[, ], trimws, whitespace = "[\\h\\v]") 
```

## Formateo

Hablamos de formateo cuando buscamos que los valores de cada celda estén el correcto tipo de dato. Para ello debemos primero ver qué tipo ha sido asignado por R.

```{r}
str(idh)
```

```{r}
str(demo)
```

-   **Conversión a tipo numérico**: Vemos que muchos valores que deberian ser numéricos han sido reconocidos como texto. Normalmente eso sucede pues hay caracteres dentro del numero que evitan que se lea adecuadamente. Luego de esa corrección recién se puede cambiar el tipo.

```{r}
# eliminar coma en los miles:
#idh$PBI = gsub(',', '', idh$PBI)
# ahora a numerico
idh[, -1] = lapply(idh[, -1], as.numeric)

# cambiar coma en los decimales:
demo[, -1] = lapply(demo[, -1],
                          function(x) {
                            gsub(",", ".", x)
                          })
# ahora a numerico
demo[, -1] = lapply(demo[, -1], as.numeric)
```

Luego de pasar a tipo numérico, las celdas que no tenían un valor numérico adecuado se convirtieron en NAs. Aquí hay que revisar las filas donde eso se generó.

```{r}
idh[!complete.cases(idh),]
```

```{r}
demo[!complete.cases(demo),]
```

A partir de lo visto, decidir si se puede completar los valores faltantes. Luego, ya nos quedamos con los datos completo.

```{r}
##
idh[idh$Pais == 'Camerún', 'EscolaridadDuracion'] = 13.1
demo[demo$Puesto == 48 & !is.na(demo$Puesto), 'Pais'] = 'Panama'

##
idh = idh[complete.cases(idh), ]
demo = demo[complete.cases(demo), ]
```

-   **Caracteres de Alfabeto español**: Es preferible eliminarlos.

```{r}
# sin tildes
idh$Pais = stri_trans_general(str = idh$Pais, 
                               id = "Latin-ASCII")

demo[, c(2, 7)] = lapply(demo[, c(2, 7)], stri_trans_general, id = "Latin-ASCII") 
```

## Merge

-   **Verificando qué falta en el campo clave**: El merge usa columnas comunes. Antes del merge definitivo hay que verificar si hay correcciones posible para que el merge no pierda tantas filas. 

Una manera práctica para darnos cuenta que NO está coincidiendo en dos conjuntos es usar diferencia de conjuntos ^[Sí A y B son conjuntos, A−B serán los elementos que están en A pero que NO están en B, por ejemplo si A={1,2,3} y B={3,5}, entonces A−B={1,2}.]:

```{r}
setdiff(demo$Pais,idh$Pais)
```

De igual manera:

```{r}
setdiff(idh$Pais,demo$Pais)
```

Se puede corroborar que sí hay valores que pueden ser corregidos.

```{r}
demo[demo$Pais=='Republica de China','Pais']='China'
demo[demo$Pais=='R. Democratica del Congo','Pais']='Republica Democratica del Congo'

```

Ahora si hay más comodidad para hacer el merge:

```{r}
idhdemo=merge(idh,demo)
head(idhdemo)
```

Tenemos un data frame que integra diversas variables que quieren medir conceptos complejos (latentes). Vemos cómo usamos el análisis factorial.


# Analisis Factorial Exploratorio (EFA)

- Explora la data y nos entrega posibles factores que resúmen cada uno un conjunto de variables.

Pasos que el EFA requiere:

1.  Subsetear la data

```{r}
dontselect = c("Pais", "Puesto", "Puntuacion", 'Categoria')
select = setdiff(names(idhdemo), dontselect)
theData = idhdemo[, select]
```

2.  Calculo de matriz de correlación:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# Polycor halla la relación policórica: funciona con variables categóricas y numéricas 
# Cuando solo se usa con numéricas, calcula el pearson, la correlación.
library(polycor)
corMatrix = polycor::hetcor(theData)$correlations
```

```{r, eval=FALSE}
La correlación es una medida estadística que indica la relación o grado de asociación entre dos variables. Se utiliza para determinar si existe una relación lineal entre las variables y en qué medida se mueven juntas. La correlación se representa por un coeficiente de correlación, que puede variar entre -1 y 1.


Un coeficiente de correlación de 1 indica una correlación positiva perfecta, lo que significa que las dos variables tienen una relación lineal directa y se mueven en la misma dirección. Por ejemplo, si una variable aumenta, la otra también lo hace en la misma proporción.


Un coeficiente de correlación de -1 indica una correlación negativa perfecta, lo que significa que las dos variables tienen una relación lineal inversa y se mueven en direcciones opuestas. Por ejemplo, si una variable aumenta, la otra disminuye en la misma proporción.


Un coeficiente de correlación cercano a 0 indica una correlación débil o nula, lo que significa que no hay una relación lineal clara entre las variables.


Es importante destacar que la correlación no implica causalidad. Solo porque dos variables estén correlacionadas no significa necesariamente que una variable cause el cambio en la otra. Puede existir una relación espuria o la influencia de una tercera variable que afecte a ambas.


Existen diferentes métodos para calcular el coeficiente de correlación, siendo el más común el coeficiente de correlación de Pearson. También existen otros coeficientes de correlación, como el coeficiente de correlación de Spearman, que se utiliza cuando las variables no tienen una relación lineal, o el coeficiente de correlación de Kendall, que se utiliza para variables ordinales.


En resumen, la correlación es una medida estadística que permite cuantificar la relación entre dos variables y proporciona información sobre cómo se mueven juntas.
```

3.  Explorar correlaciones... entre todas las variables a utilizar:

- 1er paso para comprobar las variables latentes con la teoria:
```{r coorPlot, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE, fig.cap="Matriz de Correlaciones"}

library(ggcorrplot)
ggcorrplot(corMatrix)
```

- Si puedes ver bloques correlacionados, hay esperanza de un buen analisis factorial.** Mientras más fuerte sea el color, mayor será la correlación** (en esta grafica, en otras se puede indicar de otro modo). La diagonal se ignora pues compara una variable con sí misma. 
**Si no hay correlación, se ha armado un mal índice**. Se espera que las variables de un concepto esten muy correlacionadas: INPUT para la EFA. Matriz de correlacion (algebra)

- **Todas las tecnicas de factoriales depende de la matriz de correlacion.**

  - EN SUMA: EFA: DATA Y MATRIZ DE CORRELACIÓN


4.  Verificar si los datos permiten factorizar: 

- KMO(corMatrix) <- Overall MSA > 0.6 (lo contrario sugiere cambiar esas variables)

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# Busca saber si la data se adecua a un análisis factorial. 
# El Overall MSA en este caso es 0.90, lo cual es aceptable. 
# Generalmente, se aceptan MSA mayores a 0.6 
# (lo contrario sugiere cambiar esas variables) en CC.SS. 
# KMO relacionado con el tamaño de los datos es suficiente 
# para comenzar con el EFA, respecto a la data.
library(psych)
psych::KMO(corMatrix) 
```

5.  Verificar si la matriz de correlaciones es adecuada *para donde hay factorial*

Aqui hay dos pruebas *algebraicas*:

- *Nota*: Es bueno que en ambas pruebas salgan FALSE (no puedes continuar si sale true). todavia no comienza el EFA, estos son pasos requisitos para comenzar. Pero tampoco se debe proceder con relaizar un promedio: el true ya indica que estas variables no se comportan para un promedio.

-   1. Hnula: La matriz de correlacion es una [matriz identidad](https://en.wikipedia.org/wiki/Identity_matrix)
    - De 0 a 1. 
    - 0 en las demas variables: prueba de identidad: mejor no continuar con el modelo si solo las mismas variable obtienen 1 y las demas cero.
    
```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
cortest.bartlett(corMatrix, n = nrow(theData))$p.value > 0.05
```

-   2. Hnula: La matriz de correlacion es una [matriz singular](http://mathworld.wolfram.com/SingularMatrix.html).
    - No se le puede llevar a una variable factorial, no se puede invertir

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
library(matrixcalc)

is.singular.matrix(corMatrix)
```

6.  Determinar en cuantos factores o variables latentes podríamos redimensionar la data: En este caso, la función *fa.parallel* nos dará la sugerencia:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
# Te sugiere en qué tantos factores deberían agruparse las variables en base a 
# qué tan similares son. 

# Lo ideal es que solo tengas 1 factor, pues eso significa que todas las 
# variables son lo suficientemente similares y correlacionadas para que puedan 
# agruparse en un solo concepto, en este caso, la democracia. 

# Del mismo si tienes mas variables (8 quizas) y las agrupan en 2 factores; 
# en este caso, si solo sale 1 factor, mejor buscar otras variables para los 
# conceptos que estas utilizando. Para qué inventar conceptos si al final 
# es igual con otro concepto.

# fa.parallel nos da la sugerencia de cuentos factores debemos elegir. 
# EFA: evitamos el sesgo # La medicion tambien puede fallar, en esta parte podemos advertirla. 
# Constantemente simplifacamos (inconscientemente), es parte de nosotros.

# IOT: internet de las cosas genera BIG DATA
# Mala interpretacion --> mala interpretacion (politica)
# Tecnicas no supervisadas (no darle una pista, solo las variables) el programa decide juntarlas. 
# Darle la Y (tecnica supervisada) regresiones

fa.parallel(theData, fa = 'fa', correct = T, plot = F)
```

Se sugieren 2, lo esperado, sigamos.

7.  Redimensionar a número menor de factores

-   Resultado inicial:

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
library(GPArotation)
resfa <- fa(theData,
            nfactors = 2, # Dos factores
            cor = 'mixed', # Matriz policórica
            rotate = "varimax", # Rotación varimax. Asegura que se traten 
            # de dos variables latentes diferentes 
            # en el caso que se use 1 factor, no es relevante
            fm = "minres") # Tecnica de factorizacion
print(resfa$loadings)
```

El MR1 usualmente se considera como "bueno" a partir de 0.4. En este caso, el que menos aporta es la cultura política. La proporción de la varianza nos muestra todo lo que tienen en común las variables en relación con el índice (democracia). En este caso, tienen un 76% en común, ha recuperado un 76% de información.


-   Resultado mejorado (solo apropiado si hay más de un factor):

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
print(resfa$loadings, cutoff = 0.5)
```

Cumulative Var 0.393 0.763 --> La varianza acumulada (suma de las varianzas acumuladas:): me quedo con 76% de informacion de reducir las 9 dimensiones a 2. 
  - Nota: Si hay un concepto que se encuentra en ambos factores, mejor no utilizarlo.

Cuando logramos que cada variable se vaya a un factor, tenemos una *estructura simple*.

-   Resultado visual (graficamente): 

```{r faDiagram, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE, fig.cap="Variables organizadas en Factores"}

fa.diagram(resfa,main = "Resultados del EFA")
```

8.  Evaluando Resultado obtenido:

-   ¿Qué variables aportaron mas a los factores?

```{r}
# Sort lo ordena en orden ascendente 
# Communality: podemos advertir su fuerza. para identificar cuales son las 
# variables que han contruibuido mas
sort(resfa$communality) 
```

-   ¿Qué variables contribuyen a más de un factor?

```{r}
# Se espera que este cerca a 1. advierte su comportamiento cualitativo. 
# En este caso, indica que la cultura politica se relaciona más con otras variables 
sort(resfa$complexity)
```

9.  Valores proyectados: Podemos calcular dos *indices* que resuman los dos factores encontrados.
  
- Ahora si realizamos el score (puntuacion)

```{r, echo=TRUE, eval=TRUE,warning=FALSE, message=FALSE}
as.data.frame(resfa$scores) |> head()
```

Les daremos por nombre `demos_efa` y `desahu_efa` a esas dos columnas. Dado que tenemos el indice de democracia en la data original, comparémoslo con el recién calculado, via el *scatterplot*:

El nombre sería democracia. Y debe estar correlacionado con el puntaje propuesto por TheEconomist:

  - retomamos la base del merge, no la base que paso por los requisitos
```{r scatterEFAdemo1, warning=FALSE, message=FALSE,fig.cap="Comparando Indice de Democracia con el Score obtenido en EFA"}

idhdemo$demos_efa = resfa$scores[, 1]
idhdemo$desahu_efa = resfa$scores[, 2]

ggplot(data = idhdemo, aes(x = Puntuacion, y = demos_efa)) + 
  geom_point() + theme_minimal() + 
  labs(x = "Indice de Democracia (original)", y = "Indice de Democracia EFA")
```

- Importante normalizar para comparar

Nota que los rangos de los valores en la Figura \@ref(fig:scatterEFAdemo1) no son los mismos. La Figura \@ref(fig:scatterEFAdemo2) muestra tales cambios.

```{r scatterEFAdemo2,fig.cap="Comparación Indice de Democracia con Score EFA con rangos coincidentes"}
library(BBmisc)
efa_scores_ok = normalize(resfa$scores,
                        method = "range",
                        margin = 2, # by column
                        range = c(0, 10))

idhdemo$demos_efa_ok = efa_scores_ok[, 1]
idhdemo$desahu_efa_ok = efa_scores_ok[, 2]

ggplot(data = idhdemo, aes(x = Puntuacion, y = demos_efa_ok)) + 
  geom_point() + theme_minimal() + 
  labs(x = "Indice de Democracia (original)", 
       y = "Indice de Democracia EFA (cambiado)")
```

# Análisis Factorial Confirmatorio

El análisis factorial confirmatorio (CFA) lo usamos cuando ya tenemos una teoría y queremos confirmar que los datos pueden reflejar los conceptos o variables latentes asumidas.

- Si la exploración apoyaba nuestro marco teórico, podemos proponer cómo construir los indices:
```{r}
modelCFA <- ' democracia  =~ ProcesoElectoralyPluralismo + FuncionamientodelGobierno + Participacionpolitica + Culturapolitica + Derechosciviles

desaHumano=~EsperanzaVida+EscolaridadDuracion+EscolaridadPromedio+PBI'
# =~ significa que democracia se explica por esas variables: CFA
```

Ahora vemos qué arroja el modelo:

```{r}
# normalizar las variables:
theDataNorm = scale(theData)

library(lavaan)
cfa_fit <- cfa(modelCFA, data = theDataNorm,
               std.lv = TRUE,
               missing = "fiml")
summary(cfa_fit)
```

  - *AQUI FIJARNOS EN EL LATENT VARIABLES*

Averigüemos qué tan bien salió el modelo:

```{r}
allParamCFA = parameterEstimates(cfa_fit, standardized = T)
allFitCFA = as.list(fitMeasures(cfa_fit))
```

-   El ChiSquare es NO significativo? (p_value debe ser mayor a 0.05 para que sea bueno)  Se busca que no lo sea. 
  + Si cada indicador tiene una buena conexión con su latente (ver p valor):
  + En este casi, si sale significativo

```{r}
allFitCFA[c("chisq", "df", "pvalue")] # pvalue>0.05
```

-   El Índice Tucker Lewis es mayor a 0.9?

```{r,echo=TRUE}
allFitCFA$tli # > 0.90 (no redondear)
```

-   La Raíz del error cuadrático medio de aproximación es menor a 0.05?

```{r,echo=TRUE}
# No es menor -- $rmsea [1] 0.1497624
allFitCFA[c('rmsea.ci.lower', 'rmsea' , 'rmsea.ci.upper')] # 0.05 en el Int de Conf?
```

Ya sabemos que las latentes no cumplen a cabalidad los requisitos, pero aún así calculamos las puntuaciones obtenidas por esta vía.
  - Ya sabemos que no hay buen augurio.

```{r}
scorescfa = normalize(lavPredict(cfa_fit), # lavPredict  --> para calcular los scores 
                    method = "range",
                    margin = 2, # by column
                    range = c(0, 10))

idhdemo$demos_cfa_ok = scorescfa[, 1]
idhdemo$desahu_cfa_ok = scorescfa[, 2]
```

Veamos que tanto se parece el score obtenido via CFA con la puntuación original:

- De ahi que: Veamos ambos scores calculados

```{r scatterCFAdemo,fig.cap="Comparación Indice de Democracia con Score CFA con puntuación original"}
ggplot(data = idhdemo, aes(x = Puntuacion, y = demos_cfa_ok)) + 
  geom_point() + theme_minimal() + 
  labs(x = "Indice de Democracia (original)", 
       y = "Indice de Democracia CFA (cambiado)")
```

Podemos ver los resultados del CFA en la Figura:

```{r cfaPlot, fig.cap="Representación del CFA - Democracia y IDH"}
library(lavaanPlot)
lavaanPlot(model = cfa_fit, 
           node_options = list(shape = "box", fontname = "Helvetica"), 
           edge_options = list(color = "grey"), coefs = T)

```

Podríamos hacer una regresión donde una de estas latentes es la dependiente y la otra la independiente. El siguiente paso en esta línea sería usar un modelo de **Ecuaciones Estructurales**. Primero usemos la regresión convencional, encontrando estos resultados:

```{r}
hipotesis = formula(demos_cfa_ok ~ desahu_cfa_ok)
reg1 = lm(hipotesis, data = idhdemo)
summary(reg1)
```

Ahora, usando variables latentes en una Ecuación Estructural.

```{r}

modelSEM <- ' democracia  =~ ProcesoElectoralyPluralismo + FuncionamientodelGobierno + Participacionpolitica + Culturapolitica + Derechosciviles

desaHumano=~EsperanzaVida+EscolaridadDuracion+EscolaridadPromedio+PBI

democracia~desaHumano'

```

Los resultados son:

```{r, warning=FALSE}
sem_fit <- sem(modelSEM,
               data = theDataNorm)
summary(sem_fit)
```

El resultado podemos verlo de manera gráfica en la Figura \@ref(fig:semPlot1).

```{r semPlot1, fig.cap="SEM con Democracia como dependiente e IDH como independiente"}

lavaanPlot(model = sem_fit,
           node_options = list(shape = "box",
                               fontname = "Helvetica"),
           edge_options = list(color = "grey"), coefs = T, stand = T)
```

El mismo resultado podemos verlo de manera gráfica usando otra la biblioteca *semPlot* en la Figura \@ref(fig:semPlot2).


```{r semPlot2, fig.cap="SEM alternativo con Democracia como dependiente e IDH como independiente"}
library(semPlot)
semPaths(sem_fit, residuals = F,
         sizeMan = 7, sizeLat = 12,
         what = "std",
         nCharNodes = 10,
         posCol = c("skyblue4", "red"),
         edge.color = "orange",
         edge.label.cex = 1.2, layout = "circle2")
```


  **EJERCICIO**

Añada otro concepto latente que use varias variables. Siga todos los pasos anteriores.

```{r}
demo$Country=gsub('Â'," ",demo$Country)

demo$Country =trimws(demo$Country,which=c("left"),whitespace = "[\\h\\v]")
```

```{r}
library(rio)
HDI = import("HDI_modified.xlsx")
str(HDI)
```

```{r}
HDI$Country=HDI$...1
HDI=HDI[,-1]

HDI= HDI[,c(4,1,2,3)]
```


```{r}
demo=merge(demo,HDI)
```

#replicar con nuestras bases de datos 
<br></br> <br></br> [Comienzo](#beginning) <br></br> <br></br>