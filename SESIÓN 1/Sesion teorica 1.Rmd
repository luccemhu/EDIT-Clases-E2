---
title: "Regresión Lineal Multivariada (I)"
subtitle: 'Repaso 1 - Introducción'
date: "2023-07-24"
author: "Gianfranco Romero & Joel Hu | \n **[@GianfrancoRomero](https://github.com/GianfrancoRomero)** \n a20196091@pucp.edu.pe & \n **[@luccemhu](https://github.com/luccemhu)** \n a20196510@pucp.edu.pe"
output:
  rmdformats::downcute:
    downcute_theme: "chaos"
    self_contained: true
    thumbnails: false
    lightbox: true
    gallery: false
    highlight: github
    code_folding: "show"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

I. De Correlación a regresión
============================================================

- Utilizaremos la técnica de la regresión al ir más allá de la correlación (Pearson, Spearman, etc.) o las diferencias de valores centrales (t test, kruska wallis, etc.).

```{r}
library(rio) # Importamos la data:
hsb = import("https://github.com/luccemhu/EDIT-Clases-E2/raw/main/SESI%C3%93N%201/hsb_ok.xlsx")
#str(hsb) # Tipos de datos reconocidos por R, ya que...
# Todo software lee la data a su modo y no siempre es la que se necesita.
# Por ello, debemos saber qué significa cada columna, su valor, etc.
# Para ello, es importante el codebook o diccionario de datos o metadata
# o el manual metodológico, etc. (Indicarlo en el trabajo).
```

## Preparación de los datos
```{r}
# Formateamos:
categoricals = c("SEX", "RACE", "SES", "SCTYP", "HSP", "CAR")

hsb[, categoricals] = lapply(hsb[, categoricals], as.factor) # A factor

# nominales
hsb$SEX = factor(hsb$SEX,
                 levels = c(1, 2),
                 labels = c("Male", "Female"))

hsb$RACE = factor(hsb$RACE,
                  levels = c(1, 2, 3, 4),
                  labels = c("Hispanic", "Asian", "Black", "White"))

hsb$HSP = factor(hsb$HSP,
                 levels = c(1, 2, 3),
                 labels = c("General", "Academic", "Vocational"))

hsb$SCTYP = factor(hsb$SCTYP,
                   levels = c(1, 2),
                   labels = c("Public", "Private"))

# a ordinal:
hsb$SES = ordered(hsb$SES,
                  levels = c(1, 2, 3),
                  labels = c("Low", "Medium", "High"))

#hsb #Ahora veamos la data formateada
```

## Correlación:

### La variable de interés es la V. dependiente: MATH (desempeño en matemáticas)

- Consideremos que nos interesa saber la posible relacion de WRTG en MATH

### 1. V. independiente: WRTG (desempeño en escritura)

- Ya que son `dos` variables numéricas: usaremos una correlación:
  
```{r}
# Gráfica de correlación: (2 dimensiones)
library(ggplot2)
base = ggplot(data = hsb, aes(x = WRTG, y = MATH))
base + geom_point()
# Hay aparente relación:
```

###  Índices de correlación:
```{r eval=FALSE}
# Asimétricas, correlacionadas pero ninguna es V.D. o V.I:
f1 = formula( ~ MATH + WRTG) 

# camino parametrico:
pearsonf1 = cor.test(f1, data = hsb)[c('estimate', 'p.value')]
pearsonf1
# el coeficiente de Pearson 0.6326664 (con p-value= 0).

# camino no parametrico
spearmanf1 = cor.test(f1, data = hsb, 
                      method = 'spearman')[c('estimate', 'p.value')]
spearmanf1
# Spearman:0.6415126 (con p-value= 0).
```

### 2. V. independiente: SCI (desempeño en ciencias)

Como es otra variable númerica, no podemos calcular la correlacion de 3 variables, pero sí se puede ver visualmente (Figura 10).

- Nota: *no se ejecutarán los chunks, solo se muestra el código con esta V.I*:
```{r, eval=FALSE}
# Gráfica de Correlación utilizando el código de la primera gráfica:
base + geom_point(aes(color = SCI))
```

###  Índices de correlación:
```{r, eval=FALSE}
f2 = formula( ~ MATH + SCI)

# camino parametrico
pearsonf2 = cor.test(f2, data = hsb)[c('estimate', 'p.value')]
# El coeficiente de Pearson (0.6495261, p-value= 0)

# camino no parametrico
spearmanf2 = cor.test(f2, data = hsb, method = 'spearman')[c('estimate', 'p.value')]
# El coeficiente de Spearman (0.6551515,p-value= 0)

pearsonf2
spearmanf2
```


### 3. V. independiente: SEX

```{r}
base = ggplot(data = hsb, aes(x = SEX, y = MATH))
base + geom_boxplot(notch = T) +  geom_jitter(color = "black",
                                              size = 0.4,
                                              alpha = 0.9)
```

```{r}
library(ggpubr)
ggerrorplot(data = hsb, x = "SEX", y = "MATH")
```

```{r}
ggplot(hsb, aes(x = MATH)) +
  geom_histogram(aes(y = ..density..), bins = 20, fill = 'green') +
  stat_function(fun = dnorm,
                colour = "red",
                args = list(mean = mean(hsb$MATH, na.rm = TRUE),
                            sd = sd(hsb$MATH, na.rm = TRUE))) +
  facet_grid( ~ SEX) +
  coord_flip()
```

```{r}
# se sugiere normalidad si los puntos no se alejan de la diagonal.
ggqqplot(data = hsb, x = "MATH") + facet_grid(. ~ SEX)
```

```{r}
library(knitr)
library(kableExtra)
h3 = formula(MATH ~ SEX)

# función

shapInfo = function(x) {
  y = shapiro.test(x)
  
  c(y$statistic, y$p.value)
}

tablag = aggregate(data = hsb,
                   h3,
                   FUN = shapInfo)

# para que se vea mejor:

shapiroTable = tablag[, 1] # columna 1
WandPval = as.data.frame(tablag[, 2]) # columnas 2 y 3
shapiroTable = cbind(shapiroTable, WandPval) # todo junto
names(shapiroTable)[c(1, 3)] = c("SEX", "Pval") # cambia nombre de 1 y 2da columna


kable(shapiroTable)  |> 
  kable_styling()
```

```{r}
wilcoxh3 = wilcox.test(h3, data = hsb)['p.value']
wilcoxh3
```

```{r}
base = ggplot(data = hsb, aes(x = WRTG, y = MATH))
base + geom_point(aes(color = SEX))
```

```{r}
base + geom_point(aes(size = SCI, color = SEX)) 
```

```{r}
base + geom_point(aes(color = SCI)) + facet_grid( ~ SEX)
```

```{r}
paleta <- c("coral1", "cyan")
colors <- paleta[as.numeric(hsb$SEX)]
library(scatterplot3d)

scatterplot3d(hsb[, c('SCI', 'WRTG', 'MATH')], color = colors)
```



II. Regresión Lineal
============================================================

```{r}
modelo1 = formula(MATH ~ WRTG)
modelo2 = formula(MATH ~ WRTG + SCI)
modelo3 = formula(MATH ~ WRTG + SCI + SEX)
```

```{r}
# H1: el nivel de desempeño en escritura afecta el desempeño en matemáticas:
summary(lm(modelo1, data = hsb))
```

```{r}
library(stargazer)
reg1 = lm(modelo1, data = hsb)
summary(reg1)
stargazer(reg1, type = "text", intercept.bottom = FALSE)
```


```{r}
ggplot(hsb, aes(x = WRTG, y = MATH)) +
  geom_point() +
  geom_smooth(method = lm)
```


```{r}
reg2 = lm(modelo2, data = hsb)
summary(reg2)
stargazer(reg2, type = "text", intercept.bottom = FALSE)
```

```{r}
G  <- scatterplot3d(hsb[, c('SCI', 'WRTG', 'MATH')])
G$plane3d(reg2, draw_polygon = TRUE, draw_lines = FALSE)
```

```{r}
tanova = anova(reg1, reg2)
tanova
stargazer(tanova,
          type = 'text',
          summary = F,
          title = "Table de Análisis de Varianza")
```

```{r}
reg3 = lm(modelo3, data = hsb)
summary(reg3)
```

```{r}
colors <- paleta[as.numeric(hsb$SEX)]
G  <- scatterplot3d(hsb[, c('SCI', 'WRTG', 'MATH')], color = colors)
G$plane3d(reg2, draw_polygon = TRUE, draw_lines = FALSE)
```

```{r}
stargazer(reg1, reg2, reg3, type = "text")
stargazer(reg1,
          reg2,
          reg3,
          type = "text",
          title = "Modelos planteadas",
          digits = 2,
          single.row = F,
          no.space = F,
          intercept.bottom = FALSE,
          dep.var.caption = "Variable dependiente:",
          dep.var.labels = "Desempeño en Matemáticas",
          covariate.labels = c("Constante",
                               "Desempeño en Escritura",
                               "Desempeño en Ciencias",
                               "SEXO (mujer)"),
          keep.stat = c("n", "adj.rsq", "ser"),
          df = F,
          notes.label = "Notas:")
```

```{r}
library(sjPlot)
plot_models(reg1,
            reg2,
            reg3,
            vline.color = "grey",
            m.labels = c("Modelo 1", "Modelo 2", "Modelo 3"))
```





