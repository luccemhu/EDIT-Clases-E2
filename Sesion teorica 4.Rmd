---
title: "Regresión Poisson"
author: "Gianfranco Raúl Romero Sucapuca"
date: '2022-05-06'
output: html_document
---

#Regresión Poisson

Usamos la regresión Poisson con una variable dependiente no negativa y entera que represente conteos en espacio o tiempo. Son "eventos" que ocurren en el tiempo o en un espacio determinados.

```{r}
#carga de data
linkToData = 'https://docs.google.com/spreadsheets/d/e/2PACX-1vRZEhZFOhNLGfRzpM2vrdiUxnsIuA962ZfJImNDIfwjmp65Drgp_J8rObVWNTgntRAvE39NNHee-Yp-/pub?gid=0&single=true&output=csv'

household = read.csv(linkToData)
str(household)
```

```{r}
household$roofqua = as.factor(household$roofqua)
```

Los supuestos de la regresión Poisson son:

-*Variable respuesta* Es un conteo por unidad de tiempo o espacio, que puede ser descrita por la distribución Poisson.

-*Independencia* Las observaciones no deben tener relación entre sí.

-*Media=Varianza* La media de una variable que se distribuye como Poisson debe ser igual a la varianza.

-*Linealidad* El logaritmo de la media de los datos, log(λ), debe ser una función lineal de los datos.

```{r}
library(ggplot2)
ggplot(household, aes(total)) + theme_classic() +
  geom_bar(width = 0.5) +
  xlab("Número de miembros / familia") +
  ylab("Conteo de miembros")
```

*Hipótesis* La edad del jefe de familia afecta a la cantidad de integrantes de familia

```{r}
modelo1 = formula(total ~ age)
```

```{r}
reg1 = glm(modelo1, family = poisson, data = household)
summary(reg1)
```

```{r}
library(stargazer)

stargazer(reg1,
          type = "text",
          intercept.bottom = FALSE,
          style = "all2")
```

Al probar esta hipótesis vemos, primero que age tiene efecto significativo al 0.001; segundo, que ese efecto es inverso, pues el coeficiente calculado es negativo; y tercero que la magnitud de ese efecto es -0.0047059. Para interpretar este último valor sigue estos pasos:

```{r}
edad = coef(reg1)[['age']]
E_Edad = exp(edad)
(CambioEdad = 100 * (1 - 1 / E_Edad)) #Esto es similar al efecto marginal, es decir, cuanto afecta a la probabilidad un cambio en la variable independiente.
```

Eso quiere decir que se espera que los miembros promedio del hogar disminuyan en un 0.47% cuando la edad del jefe de familia aumenta en un (01) año. Nótese que este tipo regresión propone un efecto multiplicativo sobre el valor medio de la respuesta (la regresión Gaussiana propone un efecto aditivo). Revisemos su intervalo de confianza:

```{r}
cbind(1 - 1 / exp(coef(reg1)), 1 - 1 / exp(confint(reg1)))
```

¿Y sí queremos ver el efecto de la situación económica (calidad del techo)?

```{r}
modelo2 = formula(total ~ age + roofqua)
reg2 = glm(modelo2, family = poisson, data = household)
summary(reg2)
```

Lo ideal es que AIC (Akaike) sea menor que en el modelo anterior

```{r}
#
stargazer(reg2,
          type = "text",
          intercept.bottom = FALSE,
          style = "all2")
```

Al probar esta hipótesis vemos que roofqua no tiene efecto significativo. Recuerda que sólo aparece una de las categorías del factor, y la que NO aparece es la categoría de referencia.

Es obvio a esta altura que el modelo con un solo predictor es mejor, pero podemos evaluar con anova ambos modelos:

```{r}
tanova = anova(reg1, reg2, test = "Chisq")
stargazer(tanova,
          type = 'text',
          summary = F,
          title = "Table de Análisis de Varianza")
```

La comparación de modelos usando la tabla de análisis de varianza (anova) propone como hipótesis nula que los modelos no difieren (no se ha reducido el error al pasar de un modelo a otro). Como la comparación es NO significativa (vea el Pr(>F)), no rechazamos igualdad de modelos.

Uno de los supuestos era que la media y la varianza sean iguales. Si la varianza es mayor que la media, hablamos de sobredispersión (subdispersion si es menor que la media). Veamos:

```{r}
VarY = household$total
list(media = mean(VarY),
     varianza = var(VarY),
     razon = var(VarY) / mean(VarY)
)
```

Una varianza mucho mayor que la media significa sobredispersión. Una varianza mucho menor que la media significa subdispersión. La razón permite saber si existe una sobredispersión o una subdispersión.

A veces la razon podría ser mínima, para lo cual podemos poner a prueba la hipotesis de equidispersion:

```{r}
#install.packages("AER")
library(AER)
dispersiontest(reg1)$p.value #La hipótesis nula sería que si se cumple el supuesto de la media igual a la varianza
```

Esa es la probabilidad que haya equidispersión. Así, como la varianza supera a la media, no se sostiene el supuesto pues hay sobredispersion. Veamos de solucionarlo con la quaipoisson:

```{r}
reg1quasi = glm(modelo1, family = quasipoisson, data = household)
summary(reg1quasi)
```

Los coeficientes son los mismos tanto para reg1 como para reg1quasi:

```{r}
#install.packages("arm")
library(arm)
cbind(reg1 = coef(reg1), reg1q = coef(reg1quasi))
```

Pero los errores típicos no:

```{r}
cbind(reg1 = se.coef(reg1), reg1q = se.coef(reg1quasi)
      ) #Se ve el error en el quasipoisson
```

Nota además que el mensaje “Dispersion parameter…” muestra con la quasipoisson un valor diferente a 1.

Vemos que la regresión quasipoisson lidia mejor con la sobredispersión, cuyo efecto concreto fue sobre los errores típicos. De ahí que un mejor intervalo de confianza para age será:

```{r}
cbind(1 - 1 / exp(coef(reg1quasi)), 1 - 1 / exp(confint(reg1quasi)))
```

Finalmente, una alternativa ante la sobredispersión es usar la regresión binomial negativa. Solo puede usarse cuando hay sobredispersión.

```{r}
reg1nb = glm.nb(modelo1, data = household)
summary(reg1nb)
```

Nótese que los resultados son similares a la quasipoisson. Por lo general, la binomial negativa es más utilizada que la quasipoisson, pero la binomial negativa no es apropiada para la subdispersión, mientras que la quasipoisson sí se usa para ese caso.


































